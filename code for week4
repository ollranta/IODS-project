# Olli Rantanen, Chapter 4

install.packages("MASS")
install.packages("dplyr")
install.packages("corrplot")
install.packages("ggplot2")
library(MASS)
library(dplyr)
library(corrplot)
library(ggplot2)

# Exploring the data

data("Boston")
str(Boston)
dim(Boston)
summary(Boston)

#Making the correlation matrix

cor_matrix<-cor(Boston)

cor_matrix<-cor(Boston) %>% round(digits=2)

corrplot(cor_matrix, method="circle", type = "upper", cl.pos = "b", tl.pos = "d", tl.cex = 0.6)

cor_matrix

#Scaling the data

boston_scaled <- scale(Boston)
summary(boston_scaled)
class(boston_scaled)

# Making a data frame of it

boston_scaled <- as.data.frame(boston_scaled)

# Changing to categoral values

scaled_crim <- scale(boston_scaled$crim)

summary(scaled_crim)

bins <- quantile(scaled_crim)
bins

crime <- cut(scaled_crim, breaks = bins, include.lowest = TRUE, label = c("low", "med_low", "med_high", "high"))

table(crime)

# Now we can delete the original crim from the dataset and add the new crime to it

boston_scaled <- dplyr::select(boston_scaled, -crim)
boston_scaled <- data.frame(boston_scaled, crime)


n <- nrow(boston_scaled)

ind <- sample(n,  size = n * 0.8)

train <- boston_scaled[ind,]

test <- boston_scaled[-ind,]

correct_classes <- test$crime

test <- dplyr::select(test, -crime)

# Now it's time to start the linear discriminant analysis
lda.fit <- lda(crime~. , data = train)

lda.fit

# Function for the arrows
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
  heads <- coef(x)
  arrows(x0 = 0, y0 = 0, 
         x1 = myscale * heads[,choices[1]], 
         y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
  text(myscale * heads[,choices], labels = row.names(heads), 
       cex = tex, col=color, pos=3)
}

classes <- as.numeric(train$crime)


# Then we plot the result 

plot(classes, dimen = 2, col = classes,  pch = classes)
lda.arrows(lda.fit, myscale = 1)


# Now we use the test data and cross tabulate the results
lda.pred <- predict(lda.fit, newdata = test)

table(correct = correct_classes, predicted = lda.pred$class)

# So for the final part is the clustering of the data and the
# distance measures but let's first scale the data

data("Boston")
boston_scaled1 <- scale(Boston)
summary(boston_scaled1)

dist_eu <- dist(boston_scaled1)
summary(dist_eu)

dist_man <- dist(boston_scaled1, method =  "manhattan")
summary(dist_man)

dist_eu <- dist(boston_scaled1)
# K-means
km <- kmeans(dist_eu, centers = 15)
km
pairs(boston_scaled1, col = km$cluster)

set.seed(123)
k_max <- 10

#
twcss <- sapply(1:k_max, function(k){kmeans(dist_eu, k)$tot.withinss})

# visualizing th results
plot(1:k_max, twcss, type='b')
km <-kmeans(dist_eu, centers = 2)
pairs(boston_scaled1, col = km$cluster)

# LetÂ´s try the superbonus also cause why not

model_predictors <- dplyr::select(train, -crime)

dim(model_predictors)
dim(lda.fit$scaling)

matrix_product <- as.matrix(model_predictors) %*% lda.fit$scaling
matrix_product <- as.data.frame(matrix_product)

install.packages("plotly")
library(plotly)

plot_ly(surfacecolor = train$crime, x = matrix_product$LD1, y = matrix_product$LD2, z = matrix_product$LD3, type= 'scatter3d', mode='markers')

# Unfortunately the error message saying "Webgl is not supported by your browser" keeps
# on coming and I was not able to download the wanted program for the school's computer.
# I also tried changing the plot_ly funtion but nothing seemed to work.. Maybe 1 point for a good effort ;)


#NEXT WEEK data wrangling

hd <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv", stringsAsFactors = F)
gii <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/gender_inequality.csv", stringsAsFactors = F, na.strings = "..")

# Let's explore the structure, dimensions and summaries of the data frames

dim(gii) 
# 195 rows and 10 columns

dim(hd)
# 195 rows and 8 columns

str(gii)

str(hd)

summary(hd)

summary(gii)

# Then we change better names

colnames(gii)

# > colnames(gii)
# [1] "GII.Rank"                                     "Country"                                     
# [3] "Gender.Inequality.Index..GII."                "Maternal.Mortality.Ratio"                    
# [5] "Adolescent.Birth.Rate"                        "Percent.Representation.in.Parliament"        
# [7] "Population.with.Secondary.Education..Female." "Population.with.Secondary.Education..Male."  
# [9] "Labour.Force.Participation.Rate..Female."     "Labour.Force.Participation.Rate..Male."

  colnames(gii)[1] <- "rank"
  colnames(gii)[2] <- "country"
  colnames(gii)[3] <- "GII"
  colnames(gii)[4] <- "MMR"
  colnames(gii)[5] <- "ABR"
  colnames(gii)[6] <- "PRIP"
  colnames(gii)[7] <- "PWSEF"
  colnames(gii)[8] <- "PWSEM"
  colnames(gii)[9] <- "LFPRF"
  colnames(gii)[10] <- "LFPRM"
    
  
# And do the same thing for HDI
  colnames(hd)  
 # [1] "HDI.Rank"                               "Country"                               
 # [3] "Human.Development.Index..HDI."          "Life.Expectancy.at.Birth"              
 # [5] "Expected.Years.of.Education"            "Mean.Years.of.Education"               
 # [7] "Gross.National.Income..GNI..per.Capita" "GNI.per.Capita.Rank.Minus.HDI.Rank"  
  
    colnames(hd)[1] <- "hd_rank"
    colnames(hd)[2] <- "country"
    colnames(hd)[3] <- "HDI"
    colnames(hd)[4] <- "LEAB"
    colnames(hd)[5] <- "EYOE"
    colnames(hd)[6] <- "MYOE"
    colnames(hd)[7] <- "GNI"
    colnames(hd)[8] <- "GNIR_hdrank"
    
gii <- mutate(gii, edu2F_edu2M = (PWSEF/PWSEM)) 
colnames(gii)
summary(gii)

gii <- mutate(gii, labF_labM = (LFPRF/LFPRM))

human <- inner_join(gii, hd, by = "country", suffix = c("gii", "hd"))

colnames(human)



